# internal_review
As foundation model agents become more sophisticated, guiding their system 2 reasoning to recognize important consequences of their behaviors in advance and avoid dangerous actions may be a promising pathway to safety. This repository is for exploring various implementations of this "internal review" in various agents.
